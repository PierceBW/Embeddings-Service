{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "340155ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT=/Users/pierce.bucknerwolfso/Desktop/embeddings_paper/embeddings-service-exploration\n",
      "PROJECT_SRC=/Users/pierce.bucknerwolfso/Desktop/embeddings_paper/embeddings-service-exploration/src\n",
      "RAW_DATA_DIR=/Users/pierce.bucknerwolfso/Desktop/embeddings_paper/embeddings-service-exploration/src/data/raw\n",
      "PROCESSED_DATA_DIR=/Users/pierce.bucknerwolfso/Desktop/embeddings_paper/embeddings-service-exploration/src/data/processed\n"
     ]
    }
   ],
   "source": [
    "# Notebook initialization for consistent paths (repo-aware)\n",
    "import os, sys, pathlib\n",
    "\n",
    "# Resolve repo root by walking up until we find 'src'\n",
    "CWD = pathlib.Path.cwd()\n",
    "ROOT = CWD\n",
    "for _ in range(6):\n",
    "    if (ROOT / 'src').exists():\n",
    "        break\n",
    "    ROOT = ROOT.parent\n",
    "# Fallback to current if not found\n",
    "if not (ROOT / 'src').exists():\n",
    "    ROOT = CWD\n",
    "\n",
    "PROJECT_ROOT = ROOT.resolve()\n",
    "PROJECT_SRC = PROJECT_ROOT / 'src'\n",
    "DATA_DIR = PROJECT_SRC / 'data'\n",
    "RAW_DATA_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if str(PROJECT_SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_SRC))\n",
    "\n",
    "print(f'PROJECT_ROOT={PROJECT_ROOT}')\n",
    "print(f'PROJECT_SRC={PROJECT_SRC}')\n",
    "print(f'RAW_DATA_DIR={RAW_DATA_DIR}')\n",
    "print(f'PROCESSED_DATA_DIR={PROCESSED_DATA_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bf188ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98187660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{PROCESSED_DATA_DIR}/base_loan_data_cleaned.csv')\n",
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Set the maximum column width to display full content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Set the maximum sequence items to display full list/array content\n",
    "pd.set_option('display.max_seq_items', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea466d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1369566, 74)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['loan_amnt', 'term', 'int_rate', 'sub_grade', 'emp_title', 'emp_length',\n",
       "       'home_ownership', 'annual_inc', 'verification_status', 'issue_d',\n",
       "       'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs',\n",
       "       'earliest_cr_line', 'fico_range_low', 'fico_range_high',\n",
       "       'inq_last_6mths', 'mths_since_last_delinq', 'open_acc', 'pub_rec',\n",
       "       'revol_bal', 'revol_util', 'total_acc', 'initial_list_status',\n",
       "       'collections_12_mths_ex_med', 'application_type', 'tot_coll_amt',\n",
       "       'open_acc_6m', 'open_act_il', 'open_il_12m', 'open_il_24m',\n",
       "       'total_bal_il', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util',\n",
       "       'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m',\n",
       "       'acc_open_past_24mths', 'avg_cur_bal', 'bc_open_to_buy',\n",
       "       'chargeoff_within_12_mths', 'delinq_amnt', 'mo_sin_old_il_acct',\n",
       "       'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl',\n",
       "       'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_inq',\n",
       "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
       "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
       "       'num_rev_accts', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
       "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
       "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
       "       'hardship_flag', 'loan_outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "118ee940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip xx from zip_code\n",
    "df['zip_code'] = df['zip_code'].str.replace('xx', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "596051f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = ['addr_state', 'earliest_cr_line', 'emp_length', 'emp_title', 'sub_grade', 'title', 'zip_code', 'avg_cur_bal', 'dti', 'fico_range_high', 'int_rate', 'loan_amnt', 'mort_acc', 'num_op_rev_tl', 'revol_util', 'loan_outcome']\n",
    "df = df[feature_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fa2e60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_title           6.423130\n",
      "emp_length          5.870546\n",
      "avg_cur_bal         5.132940\n",
      "num_op_rev_tl       5.131261\n",
      "mort_acc            3.652982\n",
      "title               1.237180\n",
      "revol_util          0.067467\n",
      "dti                 0.029060\n",
      "earliest_cr_line    0.002117\n",
      "zip_code            0.000073\n",
      "addr_state          0.000000\n",
      "sub_grade           0.000000\n",
      "fico_range_high     0.000000\n",
      "int_rate            0.000000\n",
      "loan_amnt           0.000000\n",
      "loan_outcome        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#find missing values & fix\n",
    "missing_percentages = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percentages.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bac0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Column: `addr_state` ---\n",
      "  Type: Categorical/String\n",
      "  Lexicographically Smallest: 'AK'\n",
      "  Lexicographically Largest: 'WY'\n",
      "  Unique Values (51 total, showing 5 examples): ['CT', 'MA', 'ND', 'NE', 'SC'] ...\n",
      "\n",
      "--- Column: `earliest_cr_line` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Categorical/String\n",
      "  Lexicographically Smallest: 'Apr-1934'\n",
      "  Lexicographically Largest: 'Sep-2015'\n",
      "  Unique Values (739 total, showing 5 examples): ['Aug-2015', 'Jan-2009', 'Jul-1984', 'Jun-1995', 'Sep-1988'] ...\n",
      "\n",
      "--- Column: `emp_length` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Categorical/String\n",
      "  Lexicographically Smallest: '1 year'\n",
      "  Lexicographically Largest: '< 1 year'\n",
      "  Unique Values (11 total, showing 5 examples): ['10+ years', '4 years', '7 years', '8 years', '< 1 year'] ...\n",
      "\n",
      "--- Column: `emp_title` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Categorical/String\n",
      "  Lexicographically Smallest: '!st Assistant Plumbing Manager'\n",
      "  Lexicographically Largest: '​License Compliance Investigator'\n",
      "  Unique Values (365164 total, showing 5 examples): ['Law enforcement Agent', 'Maple Systems', 'PBC School Board', 'Title Assistant', 'director of advancement'] ...\n",
      "\n",
      "--- Column: `sub_grade` ---\n",
      "  Type: Categorical/String\n",
      "  Lexicographically Smallest: 'A1'\n",
      "  Lexicographically Largest: 'G5'\n",
      "  Unique Values (35 total, showing 5 examples): ['A3', 'C3', 'D5', 'F1', 'F5'] ...\n",
      "\n",
      "--- Column: `title` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Categorical/String\n",
      "  Lexicographically Smallest: '\"CCC\"'\n",
      "  Lexicographically Largest: 'îîMY FIRST CAR îî'\n",
      "  Unique Values (61454 total, showing 5 examples): ['Debt. Cosolidation', 'Loan Relief', 'May 2012 Consolidation', 'credit card payoff / car repair', 'pay off second mortgage with baloon'] ...\n",
      "\n",
      "--- Column: `zip_code` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Categorical/String\n",
      "  Lexicographically Smallest: '007'\n",
      "  Lexicographically Largest: '999'\n",
      "  Unique Values (946 total, showing 5 examples): ['041', '167', '266', '307', '348'] ...\n",
      "\n",
      "--- Column: `avg_cur_bal` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Numerical\n",
      "  Lowest Value: 0.00\n",
      "  Highest Value: 958084.00\n",
      "  Unique Values (77137 total, showing 5 examples): [15897.0, 29761.0, 32309.0, 4659.0, 95993.0] ...\n",
      "\n",
      "--- Column: `dti` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Numerical\n",
      "  Lowest Value: -1.00\n",
      "  Highest Value: 999.00\n",
      "  Unique Values (7230 total, showing 5 examples): [23.75, 33.13, 51.6, 70.0, 9.12] ...\n",
      "\n",
      "--- Column: `fico_range_high` ---\n",
      "  Type: Numerical\n",
      "  Lowest Value: 614.00\n",
      "  Highest Value: 850.00\n",
      "  Unique Values (48 total, showing 5 examples): [639.0, 659.0, 734.0, 764.0, 850.0] ...\n",
      "\n",
      "--- Column: `int_rate` ---\n",
      "  Type: Numerical\n",
      "  Lowest Value: 5.31\n",
      "  Highest Value: 30.99\n",
      "  Unique Values (672 total, showing 5 examples): [10.08, 10.74, 16.14, 16.55, 9.33] ...\n",
      "\n",
      "--- Column: `loan_amnt` ---\n",
      "  Type: Numerical\n",
      "  Lowest Value: 500.00\n",
      "  Highest Value: 40000.00\n",
      "  Unique Values (1563 total, showing 5 examples): [18075.0, 21050.0, 22950.0, 23275.0, 36300.0] ...\n",
      "\n",
      "--- Column: `mort_acc` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Numerical\n",
      "  Lowest Value: 0.00\n",
      "  Highest Value: 51.00\n",
      "  Unique Values (39 total, showing 5 examples): [22.0, 3.0, 4.0, 5.0, 51.0] ...\n",
      "\n",
      "--- Column: `num_op_rev_tl` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Numerical\n",
      "  Lowest Value: 0.00\n",
      "  Highest Value: 83.00\n",
      "  Unique Values (74 total, showing 5 examples): [1.0, 27.0, 28.0, 33.0, 48.0] ...\n",
      "\n",
      "--- Column: `revol_util` ---\n",
      "  *(Note: Contains missing values)*\n",
      "  Type: Numerical\n",
      "  Lowest Value: 0.00\n",
      "  Highest Value: 892.30\n",
      "  Unique Values (1380 total, showing 5 examples): [40.2, 50.5, 72.5, 76.7, 86.1] ...\n",
      "\n",
      "--- Column: `loan_outcome` ---\n",
      "  Type: Numerical\n",
      "  Lowest Value: 0.00\n",
      "  Highest Value: 1.00\n",
      "  Unique Values (2 total): [0, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_column_summary(df, max_unique_display=5):\n",
    "    \"\"\"\n",
    "    Generates a quick summary for each column in a DataFrame, including\n",
    "    highest/lowest values and a spread of unique values (up to max_unique_display).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        max_unique_display (int): Maximum number of unique values to display.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the summary for all columns.\n",
    "    \"\"\"\n",
    "    summary_lines = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        summary_lines.append(f\"--- Column: `{col}` ---\")\n",
    "\n",
    "        # Drop NaN values for summary calculations to avoid issues\n",
    "        # and then re-add a note about NaN presence later.\n",
    "        col_data = df[col].dropna()\n",
    "\n",
    "        if col_data.empty:\n",
    "            summary_lines.append(\"  Contains no non-null values.\")\n",
    "            summary_lines.append(\"\")\n",
    "            continue\n",
    "\n",
    "        # Check for NaN presence in original column\n",
    "        if df[col].isnull().any():\n",
    "            summary_lines.append(\"  *(Note: Contains missing values)*\")\n",
    "\n",
    "        # Determine data type and get min/max\n",
    "        if pd.api.types.is_numeric_dtype(col_data):\n",
    "            summary_lines.append(f\"  Type: Numerical\")\n",
    "            summary_lines.append(f\"  Lowest Value: {col_data.min():.2f}\")\n",
    "            summary_lines.append(f\"  Highest Value: {col_data.max():.2f}\")\n",
    "        elif pd.api.types.is_datetime64_any_dtype(col_data):\n",
    "            summary_lines.append(f\"  Type: Date/Time\")\n",
    "            summary_lines.append(f\"  Earliest Date: {col_data.min().strftime('%Y-%m-%d')}\")\n",
    "            summary_lines.append(f\"  Latest Date: {col_data.max().strftime('%Y-%m-%d')}\")\n",
    "        else: # Treat as categorical/string\n",
    "            summary_lines.append(f\"  Type: Categorical/String\")\n",
    "            # For strings, min/max are lexicographical\n",
    "            summary_lines.append(f\"  Lexicographically Smallest: '{col_data.min()}'\")\n",
    "            summary_lines.append(f\"  Lexicographically Largest: '{col_data.max()}'\")\n",
    "\n",
    "        # Get unique values spread\n",
    "        unique_values = col_data.unique().tolist()\n",
    "        num_unique = len(unique_values)\n",
    "\n",
    "        if num_unique <= max_unique_display:\n",
    "            # Sort for consistent display\n",
    "            display_values = sorted(unique_values, key=str) # Use str() for mixed types if needed\n",
    "            summary_lines.append(f\"  Unique Values ({num_unique} total): {display_values}\")\n",
    "        else:\n",
    "            # Sample unique values if too many\n",
    "            # Convert to string and sample to avoid issues with non-sortable types\n",
    "            sampled_values = np.random.choice(unique_values, max_unique_display, replace=False).tolist()\n",
    "            # Sort the sampled values for consistent output\n",
    "            display_values = sorted(sampled_values, key=str)\n",
    "            summary_lines.append(f\"  Unique Values ({num_unique} total, showing {max_unique_display} examples): {display_values} ...\")\n",
    "\n",
    "        summary_lines.append(\"\") # Add a blank line for separation\n",
    "\n",
    "    return \"\\n\".join(summary_lines)\n",
    "\n",
    "# Generate the summary\n",
    "summary_output = generate_column_summary(df, max_unique_display=5)\n",
    "\n",
    "print(summary_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83f3e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_string_columns(df):\n",
    "    \"\"\"\n",
    "    Converts all string values in object-type columns to lowercase and removes\n",
    "    leading/trailing whitespace. NaN values are preserved.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with string columns standardized.\n",
    "    \"\"\"\n",
    "    df_standardized = df.copy() # Work on a copy to avoid modifying the original DataFrame directly\n",
    "\n",
    "    for col in df_standardized.columns:\n",
    "        # Check if the column's dtype is 'object' (which typically indicates strings)\n",
    "        # and if it contains any non-numeric data that might be string-like.\n",
    "        if df_standardized[col].dtype == 'object' or pd.api.types.is_string_dtype(df_standardized[col]):\n",
    "            # Apply .str.lower() and .str.strip() to string values.\n",
    "            # .str accessor handles NaN values gracefully (they remain NaN).\n",
    "            df_standardized[col] = df_standardized[col].str.lower().str.strip()\n",
    "    return df_standardized\n",
    "\n",
    "# Apply the standardization\n",
    "df = standardize_string_columns(df)\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c06bec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column 'annual_inc' not found in DataFrame for formatting.\n",
      "Warning: Column 'fico_range_low' not found in DataFrame for formatting.\n",
      "Warning: Column 'pub_rec_bankruptcies' not found in DataFrame for formatting.\n",
      "Warning: Column 'delinq_2yrs' not found in DataFrame for formatting.\n",
      "Warning: Column 'revol_bal' not found in DataFrame for formatting.\n",
      "Warning: Column 'total_acc' not found in DataFrame for formatting.\n",
      "Warning: Column 'collections_12_mths_ex_med' not found in DataFrame for formatting.\n",
      "Warning: Column 'tot_coll_amt' not found in DataFrame for formatting.\n",
      "Warning: Column 'total_rev_hi_lim' not found in DataFrame for formatting.\n",
      "Warning: Column 'acc_open_past_24mths' not found in DataFrame for formatting.\n",
      "Warning: Column 'bc_open_to_buy' not found in DataFrame for formatting.\n",
      "Warning: Column 'chargeoff_within_12_mths' not found in DataFrame for formatting.\n",
      "Warning: Column 'delinq_amnt' not found in DataFrame for formatting.\n",
      "Warning: Column 'mo_sin_old_il_acct' not found in DataFrame for formatting.\n",
      "Warning: Column 'mo_sin_old_rev_tl_op' not found in DataFrame for formatting.\n",
      "Warning: Column 'mo_sin_rcnt_rev_tl_op' not found in DataFrame for formatting.\n",
      "Warning: Column 'mo_sin_rcnt_tl' not found in DataFrame for formatting.\n",
      "Warning: Column 'mths_since_recent_bc' not found in DataFrame for formatting.\n",
      "Warning: Column 'mths_since_recent_inq' not found in DataFrame for formatting.\n",
      "Warning: Column 'num_accts_ever_120_pd' not found in DataFrame for formatting.\n",
      "Warning: Column 'num_actv_bc_tl' not found in DataFrame for formatting.\n",
      "Warning: Column 'num_actv_rev_tl' not found in DataFrame for formatting.\n",
      "Warning: Column 'num_bc_sats' not found in DataFrame for formatting.\n",
      "Warning: Column 'num_bc_tl' not found in DataFrame for formatting.\n",
      "Warning: Column 'num_il_tl' not found in DataFrame for formatting.\n",
      "Warning: Column 'num_rev_accts' not found in DataFrame for formatting.\n",
      "Warning: Column 'num_tl_90g_dpd_24m' not found in DataFrame for formatting.\n",
      "Warning: Column 'num_tl_op_past_12m' not found in DataFrame for formatting.\n",
      "Warning: Column 'pct_tl_nvr_dlq' not found in DataFrame for formatting.\n",
      "Warning: Column 'percent_bc_gt_75' not found in DataFrame for formatting.\n",
      "Warning: Column 'tax_liens' not found in DataFrame for formatting.\n",
      "Warning: Column 'tot_hi_cred_lim' not found in DataFrame for formatting.\n",
      "Warning: Column 'total_bal_ex_mort' not found in DataFrame for formatting.\n",
      "Warning: Column 'total_bc_limit' not found in DataFrame for formatting.\n",
      "Warning: Column 'inq_last_6mths' not found in DataFrame for formatting.\n",
      "Warning: Column 'open_acc' not found in DataFrame for formatting.\n",
      "Warning: Column 'pub_rec' not found in DataFrame for formatting.\n"
     ]
    }
   ],
   "source": [
    "decimal_precision_map = {\n",
    "    'loan_amnt': 0,\n",
    "    'int_rate': 2,\n",
    "    'annual_inc': 0,\n",
    "    'dti': 2,\n",
    "    'fico_range_low': 0,\n",
    "    'revol_util': 2,\n",
    "    'pub_rec_bankruptcies': 0,\n",
    "    'mort_acc': 0,\n",
    "    'delinq_2yrs': 0,\n",
    "    'revol_bal': 2,\n",
    "    'revol_util': 2,\n",
    "    'total_acc': 0,\n",
    "    'collections_12_mths_ex_med': 0,\n",
    "    'tot_coll_amt': 2,\n",
    "    'total_rev_hi_lim': 2,\n",
    "    'acc_open_past_24mths': 0,\n",
    "    'avg_cur_bal': 2,\n",
    "    'bc_open_to_buy': 2,\n",
    "    'chargeoff_within_12_mths': 0,\n",
    "    'delinq_amnt': 2,\n",
    "    'mo_sin_old_il_acct': 0,\n",
    "    'mo_sin_old_rev_tl_op': 0,\n",
    "    'mo_sin_rcnt_rev_tl_op': 0,\n",
    "    'mo_sin_rcnt_tl': 0,\n",
    "    'mort_acc': 0,\n",
    "    'mths_since_recent_bc': 0,\n",
    "    'mths_since_recent_inq': 0,\n",
    "    'num_accts_ever_120_pd': 0,\n",
    "    'num_actv_bc_tl': 0,\n",
    "    'num_actv_rev_tl': 0,\n",
    "    'num_bc_sats': 0,\n",
    "    'num_bc_tl': 0,\n",
    "    'num_il_tl': 0,\n",
    "    'num_op_rev_tl': 0,\n",
    "    'num_rev_accts': 0,\n",
    "    'num_tl_90g_dpd_24m': 0,\n",
    "    'num_tl_op_past_12m': 0,\n",
    "    'pct_tl_nvr_dlq': 1,\n",
    "    'percent_bc_gt_75': 1,\n",
    "    'pub_rec_bankruptcies': 0,\n",
    "    'tax_liens': 0,\n",
    "    'tot_hi_cred_lim': 2,\n",
    "    'total_bal_ex_mort': 2,\n",
    "    'total_bc_limit': 2,\n",
    "    'inq_last_6mths': 0,\n",
    "    'open_acc': 0,\n",
    "    'pub_rec': 0,\n",
    "}\n",
    "\n",
    "# Function to format numerical columns and convert to string with padding\n",
    "def format_numerical_to_string_with_padding(df, precision_map, nan_placeholder=\"missing_value\"):\n",
    "    \"\"\"\n",
    "    Formats specified numerical columns to a given decimal precision, pads the integer part\n",
    "    with leading zeros based on the maximum integer length in the column, and converts to strings.\n",
    "    NaN values are filled with a specified placeholder string before formatting.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        precision_map (dict): A dictionary mapping column names to desired decimal places (int).\n",
    "        nan_placeholder (str): The string to replace NaN values with before formatting.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with specified numerical columns formatted as strings.\n",
    "    \"\"\"\n",
    "    df_formatted = df.copy()\n",
    "\n",
    "    # First, calculate max integer length for each column\n",
    "    max_int_lengths = {}\n",
    "    for col, precision in precision_map.items():\n",
    "        if col in df_formatted.columns:\n",
    "            # Temporarily convert to numeric, coerce errors to NaN, then drop NaNs\n",
    "            numeric_series = pd.to_numeric(df_formatted[col], errors='coerce').dropna()\n",
    "            if not numeric_series.empty:\n",
    "                # Get the absolute value to handle negative numbers for length calculation\n",
    "                # Convert to string, split by decimal, take integer part, get length\n",
    "                max_len = numeric_series.apply(\n",
    "                    lambda x: len(str(int(abs(x)))) if pd.notna(x) else 0\n",
    "                ).max()\n",
    "                max_int_lengths[col] = int(max_len)\n",
    "            else:\n",
    "                max_int_lengths[col] = 0 # No numeric values to determine length\n",
    "\n",
    "    for col, precision in precision_map.items():\n",
    "        if col in df_formatted.columns:\n",
    "            # Get the determined max integer length for this column, default to 1 if not found\n",
    "            max_int_len = max_int_lengths.get(col, 1)\n",
    "\n",
    "            # Apply formatting and padding\n",
    "            def format_value_with_padding(val):\n",
    "                if isinstance(val, (float, int)) and not pd.isna(val):\n",
    "                    # Format to specified decimal places\n",
    "                    formatted_val = f\"{val:.{precision}f}\"\n",
    "                    \n",
    "                    # Split into integer and decimal parts\n",
    "                    parts = formatted_val.split('.')\n",
    "                    integer_part = parts[0]\n",
    "                    decimal_part = parts[1] if len(parts) > 1 else ''\n",
    "\n",
    "                    # Handle negative sign for padding\n",
    "                    sign = ''\n",
    "                    if integer_part.startswith('-'):\n",
    "                        sign = '-'\n",
    "                        integer_part = integer_part[1:]\n",
    "                    \n",
    "                    # Pad the integer part with leading zeros\n",
    "                    padded_integer_part = integer_part.zfill(max_int_len)\n",
    "                    \n",
    "                    # Reconstruct the string\n",
    "                    if precision > 0:\n",
    "                        return f\"{sign}{padded_integer_part}.{decimal_part}\"\n",
    "                    else:\n",
    "                        return f\"{sign}{padded_integer_part}\"\n",
    "                \n",
    "                # If it's NaN, return the placeholder string\n",
    "                if pd.isna(val):\n",
    "                    return nan_placeholder\n",
    "                \n",
    "                return str(val) # For any other non-numeric values, convert directly to string\n",
    "\n",
    "            df_formatted[col] = df_formatted[col].apply(format_value_with_padding)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in DataFrame for formatting.\")\n",
    "    return df_formatted\n",
    "\n",
    "# Apply the numerical formatting and string conversion with padding\n",
    "df = format_numerical_to_string_with_padding(\n",
    "    df,\n",
    "    decimal_precision_map,\n",
    "    nan_placeholder=\"missing_value\" # Consistent string for missing numericals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54c19f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>addr_state</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico_range_high</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>num_op_rev_tl</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>loan_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pa</td>\n",
       "      <td>aug-2003</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>leadman</td>\n",
       "      <td>c4</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>190</td>\n",
       "      <td>020701.00</td>\n",
       "      <td>005.91</td>\n",
       "      <td>679.0</td>\n",
       "      <td>13.99</td>\n",
       "      <td>03600</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "      <td>029.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sd</td>\n",
       "      <td>dec-1999</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>engineer</td>\n",
       "      <td>c1</td>\n",
       "      <td>business</td>\n",
       "      <td>577</td>\n",
       "      <td>009733.00</td>\n",
       "      <td>016.06</td>\n",
       "      <td>719.0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>24700</td>\n",
       "      <td>04</td>\n",
       "      <td>20</td>\n",
       "      <td>019.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>il</td>\n",
       "      <td>aug-2000</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>truck driver</td>\n",
       "      <td>b4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>605</td>\n",
       "      <td>031617.00</td>\n",
       "      <td>010.78</td>\n",
       "      <td>699.0</td>\n",
       "      <td>10.78</td>\n",
       "      <td>20000</td>\n",
       "      <td>05</td>\n",
       "      <td>04</td>\n",
       "      <td>056.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pa</td>\n",
       "      <td>jun-1998</td>\n",
       "      <td>3 years</td>\n",
       "      <td>contract specialist</td>\n",
       "      <td>f1</td>\n",
       "      <td>major purchase</td>\n",
       "      <td>174</td>\n",
       "      <td>027644.00</td>\n",
       "      <td>025.37</td>\n",
       "      <td>699.0</td>\n",
       "      <td>22.45</td>\n",
       "      <td>10400</td>\n",
       "      <td>06</td>\n",
       "      <td>07</td>\n",
       "      <td>064.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ga</td>\n",
       "      <td>oct-1987</td>\n",
       "      <td>4 years</td>\n",
       "      <td>veterinary tecnician</td>\n",
       "      <td>c3</td>\n",
       "      <td>debt consolidation</td>\n",
       "      <td>300</td>\n",
       "      <td>002560.00</td>\n",
       "      <td>010.20</td>\n",
       "      <td>694.0</td>\n",
       "      <td>13.44</td>\n",
       "      <td>11950</td>\n",
       "      <td>00</td>\n",
       "      <td>04</td>\n",
       "      <td>068.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  addr_state earliest_cr_line emp_length             emp_title sub_grade  \\\n",
       "0         pa         aug-2003  10+ years               leadman        c4   \n",
       "1         sd         dec-1999  10+ years              engineer        c1   \n",
       "2         il         aug-2000  10+ years          truck driver        b4   \n",
       "3         pa         jun-1998    3 years   contract specialist        f1   \n",
       "4         ga         oct-1987    4 years  veterinary tecnician        c3   \n",
       "\n",
       "                title zip_code avg_cur_bal     dti  fico_range_high int_rate  \\\n",
       "0  debt consolidation      190   020701.00  005.91            679.0    13.99   \n",
       "1            business      577   009733.00  016.06            719.0    11.99   \n",
       "2                 NaN      605   031617.00  010.78            699.0    10.78   \n",
       "3      major purchase      174   027644.00  025.37            699.0    22.45   \n",
       "4  debt consolidation      300   002560.00  010.20            694.0    13.44   \n",
       "\n",
       "  loan_amnt mort_acc num_op_rev_tl revol_util  loan_outcome  \n",
       "0     03600       01            04     029.70             0  \n",
       "1     24700       04            20     019.20             0  \n",
       "2     20000       05            04     056.20             0  \n",
       "3     10400       06            07     064.50             0  \n",
       "4     11950       00            04     068.40             0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e53e763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_title           6.423130\n",
      "emp_length          5.870546\n",
      "title               1.237180\n",
      "earliest_cr_line    0.002117\n",
      "zip_code            0.000073\n",
      "addr_state          0.000000\n",
      "sub_grade           0.000000\n",
      "avg_cur_bal         0.000000\n",
      "dti                 0.000000\n",
      "fico_range_high     0.000000\n",
      "int_rate            0.000000\n",
      "loan_amnt           0.000000\n",
      "mort_acc            0.000000\n",
      "num_op_rev_tl       0.000000\n",
      "revol_util          0.000000\n",
      "loan_outcome        0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "missing_percentages = (df.isnull().sum() / len(df)) * 100\n",
    "print(missing_percentages.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4eaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column 'pub_rec_bankruptcies' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'annual_inc' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'home_ownership' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'term' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'verification_status' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'issue_d' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'fico_range_low' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'collections_12_mths_ex_med' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'tot_coll_amt' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'total_rev_hi_lim' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'acc_open_past_24mths' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'bc_open_to_buy' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'chargeoff_within_12_mths' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'delinq_amnt' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'mo_sin_old_il_acct' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'mo_sin_old_rev_tl_op' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'mo_sin_rcnt_rev_tl_op' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'mo_sin_rcnt_tl' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'mths_since_recent_bc' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'mths_since_recent_inq' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_accts_ever_120_pd' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_actv_bc_tl' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_actv_rev_tl' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_bc_sats' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_bc_tl' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_il_tl' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_rev_accts' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_tl_90g_dpd_24m' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_tl_op_past_12m' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'pct_tl_nvr_dlq' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'percent_bc_gt_75' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'tax_liens' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'tot_hi_cred_lim' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'total_bal_ex_mort' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'total_bc_limit' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'inq_last_6mths' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'open_acc' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'pub_rec' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'tot_cur_bal' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'bc_util' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_rev_tl_bal_gt_0' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'num_sats' not found in DataFrame for NaN filling.\n",
      "Warning: Column 'total_il_high_credit_limit' not found in DataFrame for NaN filling.\n"
     ]
    }
   ],
   "source": [
    "# Fill NA Values\n",
    "nan_placeholders = {\n",
    "    'emp_title': \"unknown_job_title\",\n",
    "    'emp_length': \"unknown_employment_length\",\n",
    "    'title': \"unknown_loan_purpose_title\",\n",
    "    'pub_rec_bankruptcies': \"no_record\", # Assuming NaN means no record\n",
    "    'revol_util': \"unknown_revolving_utilization\",\n",
    "    # 'dti': \"unknown_debt_to_income\",\n",
    "    'earliest_cr_line': \"unknown_credit_history_start_date\",\n",
    "    'annual_inc': \"unknown_annual_income\",\n",
    "    'mort_acc': \"unknown_mortgage_accounts\",\n",
    "    # For columns with 0.000000 missingness, they might not have NaNs,\n",
    "    # but defining a placeholder is still good practice if NaNs could appear.\n",
    "    'home_ownership': \"unknown_home_ownership_status\",\n",
    "    'loan_amnt': \"unknown_loan_amount\",\n",
    "    'term': \"unknown_term\",\n",
    "    'verification_status': \"unknown_verification_status\",\n",
    "    'issue_d': \"unknown_issue_date\",\n",
    "    'addr_state': \"unknown_address_state\",\n",
    "    'fico_range_low': \"unknown_fico_score\",\n",
    "    'int_rate': \"unknown_interest_rate\",\n",
    "    'loan_outcome': \"unknown_loan_outcome_status\", # Though this might be removed later as leakage\n",
    "    'collections_12_mths_ex_med': \"unknown_collections_12m\",\n",
    "    'tot_coll_amt': \"unknown_total_collection_amount\",\n",
    "    'total_rev_hi_lim': \"unknown_total_revolving_high_limit\",\n",
    "    'acc_open_past_24mths': \"unknown_accounts_opened_24m\",\n",
    "    # 'avg_cur_bal': \"unknown_average_current_balance\",\n",
    "    'bc_open_to_buy': \"unknown_bankcard_open_to_buy\",\n",
    "    'chargeoff_within_12_mths': \"unknown_chargeoffs_12m\",\n",
    "    'delinq_amnt': \"unknown_delinquent_amount\",\n",
    "    'mo_sin_old_il_acct': \"unknown_months_since_old_il_account\",\n",
    "    'mo_sin_old_rev_tl_op': \"unknown_months_since_old_revolving_account\",\n",
    "    'mo_sin_rcnt_rev_tl_op': \"unknown_months_since_recent_revolving_account\",\n",
    "    'mo_sin_rcnt_tl': \"unknown_months_since_recent_account\",\n",
    "    'mort_acc': \"unknown_mortgage_accounts\",\n",
    "    'mths_since_recent_bc': \"unknown_months_since_recent_bankcard\",\n",
    "    'mths_since_recent_inq': \"unknown_months_since_recent_inquiry\",\n",
    "    'num_accts_ever_120_pd': \"unknown_accounts_ever_120_pd\",\n",
    "    'num_actv_bc_tl': \"unknown_active_bankcard_accounts\",\n",
    "    'num_actv_rev_tl': \"unknown_active_revolving_accounts\",\n",
    "    'num_bc_sats': \"unknown_satisfactory_bankcard_accounts\",\n",
    "    'num_bc_tl': \"unknown_bankcard_accounts\",\n",
    "    'num_il_tl': \"unknown_installment_accounts\",\n",
    "    'num_op_rev_tl': \"unknown_open_revolving_accounts\",\n",
    "    'num_rev_accts': \"unknown_revolving_accounts\",\n",
    "    'num_tl_90g_dpd_24m': \"unknown_90_dpd_24m\",\n",
    "    'num_tl_op_past_12m': \"unknown_accounts_opened_12m\",\n",
    "    'pct_tl_nvr_dlq': \"unknown_percent_never_delinquent\",\n",
    "    'percent_bc_gt_75': \"unknown_percent_bc_gt_75\",\n",
    "    'tax_liens': \"unknown_tax_liens\",\n",
    "    'tot_hi_cred_lim': \"unknown_total_high_credit_limit\",\n",
    "    'total_bal_ex_mort': \"unknown_total_balance_ex_mortgage\",\n",
    "    'total_bc_limit': \"unknown_total_bankcard_limit\",\n",
    "    'inq_last_6mths': \"unknown_inquiries_6m\",\n",
    "    'open_acc': \"unknown_open_accounts\",\n",
    "    'pub_rec': \"unknown_public_records\",\n",
    "    'tot_cur_bal': \"unknown_total_current_balance\",\n",
    "    'bc_util': \"unknown_bankcard_utilization\",\n",
    "    'num_rev_tl_bal_gt_0': \"unknown_revolving_accounts_with_balance\",\n",
    "    'num_sats': \"unknown_satisfactory_bankcard_accounts\",\n",
    "    'total_il_high_credit_limit': \"unknown_total_installment_high_credit_limit\",\n",
    "    \n",
    "}\n",
    "\n",
    "# --- Function to fill NaNs with domain-specific placeholders ---\n",
    "def fill_nans_with_domain_specific_placeholders(df, placeholders_map):\n",
    "    \"\"\"\n",
    "    Fills NaN values in specified columns of a DataFrame with domain-specific string placeholders.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        placeholders_map (dict): A dictionary mapping column names to their NaN placeholder strings.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with NaNs filled according to the map.\n",
    "    \"\"\"\n",
    "    df_filled = df.copy()\n",
    "\n",
    "    for col, placeholder in placeholders_map.items():\n",
    "        if col in df_filled.columns:\n",
    "            # Ensure the column is of a type that can hold strings, or convert it\n",
    "            # if it's purely numeric and will be converted to string later.\n",
    "            # Using .astype(str) before fillna can be an option for consistency,\n",
    "            # but fillna itself will often coerce to object dtype if needed.\n",
    "            df_filled[col] = df_filled[col].fillna(placeholder)\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in DataFrame for NaN filling.\")\n",
    "    return df_filled\n",
    "\n",
    "# Apply the NaN filling\n",
    "df = fill_nans_with_domain_specific_placeholders(df, nan_placeholders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db2557c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip_code            1\n",
       "addr_state          0\n",
       "earliest_cr_line    0\n",
       "emp_length          0\n",
       "emp_title           0\n",
       "sub_grade           0\n",
       "title               0\n",
       "avg_cur_bal         0\n",
       "dti                 0\n",
       "fico_range_high     0\n",
       "int_rate            0\n",
       "loan_amnt           0\n",
       "mort_acc            0\n",
       "num_op_rev_tl       0\n",
       "revol_util          0\n",
       "loan_outcome        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaNs in the data\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd980a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "#df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7d9416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1369565 entries, 0 to 1369565\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   addr_state        1369565 non-null  object \n",
      " 1   earliest_cr_line  1369565 non-null  object \n",
      " 2   emp_length        1369565 non-null  object \n",
      " 3   emp_title         1369565 non-null  object \n",
      " 4   sub_grade         1369565 non-null  object \n",
      " 5   title             1369565 non-null  object \n",
      " 6   zip_code          1369565 non-null  object \n",
      " 7   avg_cur_bal       1369565 non-null  object \n",
      " 8   dti               1369565 non-null  object \n",
      " 9   fico_range_high   1369565 non-null  float64\n",
      " 10  int_rate          1369565 non-null  object \n",
      " 11  loan_amnt         1369565 non-null  object \n",
      " 12  mort_acc          1369565 non-null  object \n",
      " 13  num_op_rev_tl     1369565 non-null  object \n",
      " 14  revol_util        1369565 non-null  object \n",
      " 15  loan_outcome      1369565 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(14)\n",
      "memory usage: 177.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1195963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_outcome\n",
      "0    0.78765\n",
      "1    0.21235\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Now, check the new value counts\n",
    "print(df['loan_outcome'].value_counts()/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38aa7c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df for embeddings\n",
    "df.to_csv(f'{PROCESSED_DATA_DIR}/final_features_for_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EmbeddingService",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
