{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463bb0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT=/Users/pierce.bucknerwolfso/Desktop/embeddings_paper/embeddings-service-exploration\n",
      "PROJECT_SRC=/Users/pierce.bucknerwolfso/Desktop/embeddings_paper/embeddings-service-exploration/src\n",
      "RAW_DATA_DIR=/Users/pierce.bucknerwolfso/Desktop/embeddings_paper/embeddings-service-exploration/src/data/raw\n",
      "PROCESSED_DATA_DIR=/Users/pierce.bucknerwolfso/Desktop/embeddings_paper/embeddings-service-exploration/src/data/processed\n"
     ]
    }
   ],
   "source": [
    "# Notebook initialization for consistent paths (repo-aware)\n",
    "import os, sys, pathlib\n",
    "\n",
    "# Resolve repo root by walking up until we find 'src'\n",
    "CWD = pathlib.Path.cwd()\n",
    "ROOT = CWD\n",
    "for _ in range(6):\n",
    "    if (ROOT / 'src').exists():\n",
    "        break\n",
    "    ROOT = ROOT.parent\n",
    "# Fallback to current if not found\n",
    "if not (ROOT / 'src').exists():\n",
    "    ROOT = CWD\n",
    "\n",
    "PROJECT_ROOT = ROOT.resolve()\n",
    "PROJECT_SRC = PROJECT_ROOT / 'src'\n",
    "DATA_DIR = PROJECT_SRC / 'data'\n",
    "RAW_DATA_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if str(PROJECT_SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_SRC))\n",
    "\n",
    "print(f'PROJECT_ROOT={PROJECT_ROOT}')\n",
    "print(f'PROJECT_SRC={PROJECT_SRC}')\n",
    "print(f'RAW_DATA_DIR={RAW_DATA_DIR}')\n",
    "print(f'PROCESSED_DATA_DIR={PROCESSED_DATA_DIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf188ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/EmbeddingService/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98187660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n7/_vnphx3n0hjd52f_bckm4r1w0000gp/T/ipykernel_26418/1299423283.py:1: DtypeWarning: Columns (7,8,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'{PROCESSED_DATA_DIR}/final_features_for_embeddings.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{PROCESSED_DATA_DIR}/final_features_for_embeddings.csv')\n",
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Set the maximum column width to display full content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Set the maximum sequence items to display full list/array content\n",
    "pd.set_option('display.max_seq_items', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea466d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1369565, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['addr_state', 'earliest_cr_line', 'emp_length', 'emp_title',\n",
       "       'sub_grade', 'title', 'zip_code', 'avg_cur_bal', 'dti',\n",
       "       'fico_range_high', 'int_rate', 'loan_amnt', 'mort_acc', 'num_op_rev_tl',\n",
       "       'revol_util', 'loan_outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5532e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan_amnt', 'int_rate', 'dti', 'avg_cur_bal', 'revol_util', 'num_op_rev_tl', 'mort_acc', 'fico_range_high']\n",
      "['title', 'emp_title', 'emp_length', 'addr_state', 'sub_grade', 'earliest_cr_line', 'zip_code']\n"
     ]
    }
   ],
   "source": [
    "# numerical vs catagorical/text columns\n",
    "numerical_cols = ['loan_amnt', 'int_rate', 'dti', 'avg_cur_bal', 'revol_util', 'num_op_rev_tl', 'mort_acc', 'fico_range_high']\n",
    "string_cols = ['title', 'emp_title', 'emp_length', 'addr_state', 'sub_grade', 'earliest_cr_line', 'zip_code']\n",
    "\n",
    "print(numerical_cols)\n",
    "print(string_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d9416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1369565 entries, 0 to 1369564\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count    Dtype  \n",
      "---  ------            --------------    -----  \n",
      " 0   addr_state        1369565 non-null  object \n",
      " 1   earliest_cr_line  1369565 non-null  object \n",
      " 2   emp_length        1369565 non-null  object \n",
      " 3   emp_title         1369565 non-null  object \n",
      " 4   sub_grade         1369565 non-null  object \n",
      " 5   title             1369565 non-null  object \n",
      " 6   zip_code          1369565 non-null  int64  \n",
      " 7   avg_cur_bal       1369565 non-null  object \n",
      " 8   dti               1369565 non-null  object \n",
      " 9   fico_range_high   1369565 non-null  float64\n",
      " 10  int_rate          1369565 non-null  float64\n",
      " 11  loan_amnt         1369565 non-null  int64  \n",
      " 12  mort_acc          1369565 non-null  object \n",
      " 13  num_op_rev_tl     1369565 non-null  object \n",
      " 14  revol_util        1369565 non-null  object \n",
      " 15  loan_outcome      1369565 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(11)\n",
      "memory usage: 167.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9690c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DICE1:\n",
    "    '''\n",
    "    DICE class turns numbers into their respective DICE embeddings\n",
    "    \n",
    "    Since the cosine function decreases monotonically between 0 and pi, simply employ a linear mapping\n",
    "    to map distances s_n \\in [0, |a-b|] to angles \\theta \\in [0, pi]\n",
    "    '''\n",
    "    def __init__(self, d=2, min_bound=0, max_bound=100, norm=\"l2\"):\n",
    "        self.d = d # By default, we build DICE-2\n",
    "        self.min_bound = min_bound\n",
    "        self.max_bound = max_bound\n",
    "        self.norm = norm  # Restrict x and y to be of unit length\n",
    "        self.M = np.random.normal(0, 1, (self.d, self.d))\n",
    "        self.Q, self.R = np.linalg.qr(self.M, mode=\"complete\")  # QR decomposition for orthonormal basis, Q\n",
    "    \n",
    "    def __linear_mapping(self, num):\n",
    "        '''Eq. (4) from DICE'''\n",
    "        norm_diff = num / abs(self.min_bound - self.max_bound)\n",
    "        theta = norm_diff * math.pi\n",
    "        return theta\n",
    "    \n",
    "    def make_dice(self, num):\n",
    "        r = 1\n",
    "        theta = self.__linear_mapping(num)\n",
    "        if self.d == 2:\n",
    "            # DICE-2\n",
    "            polar_coord = np.array([r*math.cos(theta), r*math.sin(theta)])\n",
    "        elif self.d > 2:\n",
    "            # DICE-D\n",
    "            polar_coord = np.array([math.sin(theta)**(dim-1) * math.cos(theta) if dim < self.d else math.sin(theta)**(self.d) for dim in range(1, self.d+1)])\n",
    "        else:\n",
    "            raise ValueError(\"Wrong value for `d`. `d` should be greater than or equal to 2.\")\n",
    "            \n",
    "        dice = np.dot(self.Q, polar_coord)  # DICE-D embedding for `num`\n",
    "        \n",
    "        # return dice.tolist()\n",
    "        return dice\n",
    "\n",
    "class DICE:\n",
    "    '''\n",
    "    DICE class turns numbers into their respective DICE embeddings\n",
    "    \n",
    "    Since the cosine function decreases monotonically between 0 and pi, simply employ a linear mapping\n",
    "    to map distances s_n \\in [0, |a-b|] to angles \\theta \\in [0, pi]\n",
    "    '''\n",
    "    def __init__(self, d=2, min_bound=0, max_bound=100, norm=\"l2\", seed: int = 13):\n",
    "        # Minimal POC tweaks:\n",
    "        # - deterministic basis via fixed seed\n",
    "        # - keep API mostly the same\n",
    "        if d < 2:\n",
    "            raise ValueError(\"Wrong value for `d`. `d` should be greater than or equal to 2.\")\n",
    "        self.d = int(d)  # By default, we build DICE-2\n",
    "        self.min_bound = float(min_bound)\n",
    "        self.max_bound = float(max_bound)\n",
    "        self.norm = norm  # If \"l2\", return a unit vector\n",
    "        self.seed = int(seed)\n",
    "\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        self.M = rng.normal(0.0, 1.0, (self.d, self.d))\n",
    "        self.Q, self.R = np.linalg.qr(self.M, mode=\"complete\")  # Orthonormal basis Q\n",
    "    \n",
    "    def __linear_mapping(self, num):\n",
    "        \"\"\"Map value linearly from [min_bound, max_bound] to angle in [0, pi].\n",
    "        Clamps outside values. Guards against zero range.\n",
    "        \"\"\"\n",
    "        span = self.max_bound - self.min_bound\n",
    "        if span == 0:\n",
    "            return 0.0\n",
    "        t = (float(num) - self.min_bound) / span\n",
    "        # clamp to [0, 1]\n",
    "        if t < 0.0:\n",
    "            t = 0.0\n",
    "        elif t > 1.0:\n",
    "            t = 1.0\n",
    "        theta = t * math.pi\n",
    "        return theta\n",
    "    \n",
    "    def make_dice(self, num):\n",
    "        r = 1.0\n",
    "        theta = self.__linear_mapping(num)\n",
    "        if self.d == 2:\n",
    "            # DICE-2\n",
    "            polar_coord = np.array([r * math.cos(theta), r * math.sin(theta)], dtype=np.float32)\n",
    "        elif self.d > 2:\n",
    "            # DICE-D\n",
    "            polar_coord = np.array([\n",
    "                (math.sin(theta) ** (dim - 1)) * math.cos(theta) if dim < self.d else (math.sin(theta) ** (self.d))\n",
    "                for dim in range(1, self.d + 1)\n",
    "            ], dtype=np.float32)\n",
    "        else:\n",
    "            # Guarded in __init__, but keep for safety\n",
    "            raise ValueError(\"Wrong value for `d`. `d` should be greater than or equal to 2.\")\n",
    "\n",
    "        dice = np.dot(self.Q.astype(np.float32, copy=False), polar_coord)  # DICE-D embedding for `num`\n",
    "\n",
    "        if self.norm == \"l2\":\n",
    "            n = float(np.linalg.norm(dice))\n",
    "            if n > 0:\n",
    "                dice = dice / n\n",
    "\n",
    "        return dice.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411dd4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09091438  0.26237428 -0.05515493  0.6389749   0.22175486  0.08626071\n",
      " -0.5020955  -0.38060957  0.13628195  0.1985221 ]\n",
      "[ 0.4410594  -0.41056359  0.06392424 -0.41668609 -0.29017277 -0.13924215\n",
      "  0.39882476 -0.17491829  0.18540026  0.36272728]\n",
      "[ 0.09091438  0.26237428 -0.05515493  0.6389749   0.22175486  0.08626071\n",
      " -0.5020955  -0.38060957  0.13628195  0.1985221 ]\n",
      "[ 0.4410594  -0.41056359  0.06392424 -0.41668609 -0.29017277 -0.13924215\n",
      "  0.39882476 -0.17491829  0.18540026  0.36272728]\n",
      "[ 0.09091438  0.26237428 -0.05515493  0.6389749   0.22175486  0.08626071\n",
      " -0.5020955  -0.38060957  0.13628195  0.1985221 ]\n",
      "[ 0.4410594  -0.41056359  0.06392424 -0.41668609 -0.29017277 -0.13924215\n",
      "  0.39882476 -0.17491829  0.18540026  0.36272728]\n"
     ]
    }
   ],
   "source": [
    "# DICE Embeddings examples\n",
    "d = DICE(d=10, min_bound=0, max_bound=10, norm=\"l2\", seed=42)\n",
    "d1 = DICE1(d=10, min_bound=0, max_bound=10)\n",
    "\n",
    "print(d.make_dice(10))\n",
    "print(d1.make_dice(10))\n",
    "\n",
    "print(d.make_dice(10))\n",
    "print(d1.make_dice(10))\n",
    "\n",
    "print(d.make_dice(10))\n",
    "print(d1.make_dice(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a21c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "# Load data\n",
    "df = df.drop_duplicates()\n",
    "feature_cols = df.columns.drop('loan_outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c439ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df.drop(columns=['loan_outcome'])\n",
    "y_full = df['loan_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75e7f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnarHybridEmbedder:\n",
    "    def __init__(self, text_cols, numerical_cols, text_model_name='all-MiniLM-L6-v2'):\n",
    "        self.text_cols = sorted(text_cols)\n",
    "        self.numerical_cols = sorted(numerical_cols)\n",
    "        self.feature_order = self.text_cols + self.numerical_cols\n",
    "        \n",
    "        self.model_name = text_model_name\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "        print(f\"Using device: {device}\")\n",
    "        self.text_model = SentenceTransformer(self.model_name, device=device)\n",
    "        self.numerical_embedders = {}\n",
    "        self.feature_map = {}\n",
    "        self.numerical_embedding_dim = 0\n",
    "\n",
    "    def fit(self, df, numerical_embedding_dim=32):\n",
    "        print(\"Fitting embedders and building feature map...\")\n",
    "        self.numerical_embedding_dim = numerical_embedding_dim\n",
    "\n",
    "        for col in self.numerical_cols:\n",
    "            numeric_col = pd.to_numeric(df[col], errors='coerce')\n",
    "            min_val = numeric_col.min()\n",
    "            max_val = numeric_col.max()\n",
    "            print(f\"bounds for {col}: {min_val} to {max_val}\")\n",
    "            self.numerical_embedders[col] = DICE(d=numerical_embedding_dim,\n",
    "                                     min_bound=min_val,\n",
    "                                     max_bound=max_val)\n",
    "        \n",
    "        current_index = 0\n",
    "        text_dim = self.text_model.get_sentence_embedding_dimension()\n",
    "        for col in self.feature_order:\n",
    "            start_index = current_index\n",
    "            if col in self.text_cols:\n",
    "                end_index = start_index + text_dim\n",
    "                current_index += text_dim\n",
    "            elif col in self.numerical_cols:\n",
    "                end_index = start_index + self.numerical_embedding_dim\n",
    "                current_index += self.numerical_embedding_dim\n",
    "            self.feature_map[col] = (start_index, end_index)\n",
    "            \n",
    "        print(\"Fit complete.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, output_name, batch_size=64):\n",
    "        print(f\"Generating embeddings for {len(df)} rows...\")\n",
    "        \n",
    "        # 1. Calculate the final shape of the array beforehand\n",
    "        num_rows = len(df)\n",
    "        text_dim = self.text_model.get_sentence_embedding_dimension()\n",
    "        total_dims = (len(self.text_cols) * text_dim) + (len(self.numerical_cols) * self.numerical_embedding_dim)\n",
    "        final_shape = (num_rows, total_dims)\n",
    "        \n",
    "        # 2. Create the memory-mapped file on disk\n",
    "        output_path = f'{PROCESSED_DATA_DIR}/{output_name}.npy'\n",
    "        print(f\"Creating memory-mapped file at: {output_path} with shape {final_shape}\")\n",
    "        final_embeddings = np.memmap(output_path, dtype='float32', mode='w+', shape=final_shape)\n",
    "\n",
    "        # 3. Fill the memmap array column by column\n",
    "        for col in tqdm(self.feature_order, desc=\"Embedding and saving columns\"):\n",
    "            start_idx, end_idx = self.feature_map[col] # Get indices from the map\n",
    "            \n",
    "            if col in self.text_cols:\n",
    "                sentences = df[col].astype(str).tolist()\n",
    "                embs = self.text_model.encode(\n",
    "                    sentences, batch_size=batch_size, show_progress_bar=False, normalize_embeddings=True, convert_to_numpy=True\n",
    "                )\n",
    "                # Assign directly to the slice in the file on disk\n",
    "                final_embeddings[:, start_idx:end_idx] = embs\n",
    "            \n",
    "            elif col in self.numerical_cols:\n",
    "                # This part can be optimized significantly by avoiding the Python loop\n",
    "                embedder = self.numerical_embedders[col]\n",
    "                \n",
    "                # Vectorized approach to handle missing values\n",
    "                vals = pd.to_numeric(df[col], errors='coerce').values\n",
    "                is_nan = np.isnan(vals)\n",
    "                \n",
    "                # Create embeddings for valid numbers\n",
    "                valid_embs = np.array([embedder.make_dice(v) for v in vals[~is_nan]])\n",
    "                \n",
    "                # Create a temporary full array and fill it\n",
    "                col_embs = np.zeros((num_rows, self.numerical_embedding_dim), dtype='float32')\n",
    "                col_embs[~is_nan] = valid_embs\n",
    "                \n",
    "                # Assign the entire column's embeddings at once\n",
    "                final_embeddings[:, start_idx:end_idx] = col_embs\n",
    "\n",
    "            # 4. Flush changes to disk and clean up memory\n",
    "            final_embeddings.flush()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"Transformation complete. Embeddings saved.\")\n",
    "        \n",
    "        # The embeddings are already saved, so we only need to save the labels\n",
    "        labels = y_full.astype(np.int8).values # Make sure y_full is defined\n",
    "        np.save(f'{PROCESSED_DATA_DIR}/{output_name}_labels.npy', labels)\n",
    "        \n",
    "        return \"Embedding generation complete. Files saved.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Fitting embedders and building feature map...\n",
      "bounds for avg_cur_bal: 0.0 to 958084.0\n",
      "bounds for dti: -1.0 to 999.0\n",
      "bounds for fico_range_high: 614.0 to 850.0\n",
      "bounds for int_rate: 5.31 to 30.99\n",
      "bounds for loan_amnt: 500 to 40000\n",
      "bounds for mort_acc: 0.0 to 51.0\n",
      "bounds for num_op_rev_tl: 0.0 to 83.0\n",
      "bounds for revol_util: 0.0 to 892.3\n",
      "Fit complete.\n",
      "Generating embeddings for 1369565 rows...\n",
      "Creating memory-mapped file at: /Users/pierce.bucknerwolfso/Desktop/embeddings_paper/embeddings-service-exploration/src/data/processed/hybrid_embeddings.npy with shape (1369565, 2944)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding and saving columns:  27%|██▋       | 4/15 [20:21<57:14, 312.22s/it]  "
     ]
    }
   ],
   "source": [
    "# Create hybrid embeddings\n",
    "hybrid_embedder = ColumnarHybridEmbedder(text_cols=string_cols, numerical_cols=numerical_cols)\n",
    "hybrid_embedder.fit(df, numerical_embedding_dim=32) # Using d=32 for DICE\n",
    "hybrid_embedder.transform(df, output_name='hybrid_embeddings');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a88027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Map ---\n",
      "{'addr_state': (0, 384), 'avg_cur_bal': (384, 768), 'dti': (768, 1152), 'earliest_cr_line': (1152, 1536), 'emp_length': (1536, 1920), 'emp_title': (1920, 2304), 'fico_range_high': (2304, 2688), 'int_rate': (2688, 3072), 'loan_amnt': (3072, 3456), 'mort_acc': (3456, 3840), 'num_op_rev_tl': (3840, 4224), 'revol_util': (4224, 4608), 'sub_grade': (4608, 4992), 'title': (4992, 5376), 'zip_code': (5376, 5760)}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Feature Map ---\")\n",
    "f_map = {}\n",
    "for feature, (start, end) in hybrid_embedder.feature_map.items():\n",
    "    f_map[feature] = (start, end)\n",
    "print(f_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb22c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create string only embeddings\n",
    "hybrid_embedder = ColumnarHybridEmbedder(text_cols=string_cols + numerical_cols, numerical_cols=[])\n",
    "hybrid_embedder.fit(df, numerical_embedding_dim=32) # Using d=32 for DICE\n",
    "hybrid_embedder.transform(df, output_name='text_only_embeddings');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ea9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Feature Map ---\")\n",
    "f_map = {}\n",
    "for feature, (start, end) in hybrid_embedder.feature_map.items():\n",
    "    f_map[feature] = (start, end)\n",
    "print(f_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EmbeddingService",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
